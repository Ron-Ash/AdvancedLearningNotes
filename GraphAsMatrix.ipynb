# Graph as Matrix
Graph analysis and matrix perspective can help with undertand the connection between random walks, matrix factorization and node embeddings.

## Link Analysis
In the early days of the web links were navigational (today many are transactional), used to tranverse between pages; meaning that it can be represented as a directional graph (same can be done with article citations, etc.). All web pages are not equally important, which can be observed through the diversity in the web-graph node connectivity (important pages are linked to more than unimportant pages, etc.); and so importance (rank) can be derived through link analysis approaches.

### PageRank
As the web is a directed graph, it can be rationalised that in-coming links are more important than out-going links as the former is harder fake than the latter. Also, links from important pages are more significant that ones from unimportant pages (recustive question).

<table><tr><td>

![image.png](attachment:image.png)
</td><td>

This can be formalised as each link's "vote" is proportional to the importance of its source page; if page $i$ with importance $r_i$ has $d_i$ out-links, each link has $r_i/d_i$ votes, and page $j$'s own importance $r_j$ is the sum of the votes on its in-links: $$r_j=\sum_{i\rightarrow j}\frac{r_i}{d_i}$$
</td></tr></table>

While this creates a system of equations which can be solved using gaussian elimination, it is computationally expensive; instead, using **stochastic adjancency matrix**, $M$ (if $j\rightarrow i$, then $M_{ij}=1/d_j$), a solution can be achieved more efficiently.

Let $r$ be a rank vector with an entry per page such that $\sum_ir_i=1$, and so the above equation can be re-written using these new matrices:$$r_j=\sum_{i\rightarrow j}\frac{r_i}{d_i}\rightarrow r=M\cdot r$$

- This idea can be connected back to random walks where it can be imagined that at any time $t$, a web-surfer is on some page $i$ and at $t+1$ they follow an out-link from $i$ at (uniform) random to some other page $j$. The stochastic adjacency matrix then is the probability of a surfer from page $i$ travelling to page $j$, $M_{ji}=1/d_i$, with the probability of the surfer being at any given page at time $t+1$ being $p(t+1)=M\cdot p(t)$ ($p(t)$ is a vector whose $i^{th}$ element is the probability that the surfer is at page $i$ at time $t$). Suppose now that the random walk reaches a state where $p(t+1)=M\cdot p(t)=p(t)$, the $p(t)$ is the stationary distributuion of a random walk (from this point onwards, the probability of surfer being at any page stays the same regardless of time spent walking).
- This idea can also be connected to **eigenvector centrality** (node-level feature), $\lambda c=Ac$;where instead of an undirected adjacency matrix and $\lambda$, this uses a directed stochastic adjancency matrix and $\lambda=1$

And so the rank vector, $r$, is the (principal) eigenvector of the stochastic adjacency matrix $M$ with eigenvalue of 1, corresponding to the limit distribution of the product $MM\ldots Mu$. Solving for $r$ can be efficiently solved through **power iteration**:
### Personalized PageRank
### Random Walk with Restarts

